[{"title":"博客添加了脚标功能！","url":"/2021/footnotes-test/","content":"这是一篇用来测试脚标功能的测试贴。今天想给博客整个脚标参考文献功能，搜索一番发现并没有合适的包。于是花了一下午时间，基于 hexo-reference[1] 重写了下，修复了一些 Bug。然后主要是把解析器改成了博客正在用的 marked（原包使用的 markdown-it ），以及把原来的 Hint.css 改为更加好看的 Tippy.js[2]。\n功能测试Markdown 原文\n\n\n渲染结果\n\n基本脚注[3]，点击可以跳转到相应的参考文献。\n这是行内脚标[4]，行内脚标支持 Markdown。\n这是个带图片的脚标[5]\n\n\n渲染结果就是上面这样子啦！桌面端鼠标放在上标上会有内容弹窗[6]，触屏设备则需要按住不动 0.5 秒，该行为可以在 Tippy.js 中设置[7]。\nTODO\n有时间打包成插件公开出来；\n目前使用的正则表达式替换比较“暴力”，之后试试能不能优化一下；\n[已解决] 定位不准的问题；\n定位后高亮提示;\na 链接与 touch 操作矛盾；\n引用自动编号功能；\n同一文献多处引用的功能；\n\nReference[1]hexo-reference 仓库  ↩[2]Tippy.js 官网  ↩[3]基本脚注。  ↩[4]行内参考文献  ↩[5]图片脚标 \n  ↩[6]内容弹窗  ↩[7]Tippy.js &gt; All Props &gt; touch  ↩","categories":["技术","Hexo"],"tags":["Hexo","脚标","参考文献"]},{"title":"你好，世界","url":"/2021/hello-world/","content":"这个人很忙，正在复习《凸优化方法》，一会儿回来…\n\n\n测试目录我爱优化方法\n测试测试公式\n\n\n测试图片\n测试代码print('我爱优化方法')","categories":["日常"],"tags":["Hello World"]},{"title":"论文笔记：Orthogonal Projection Loss","url":"/2021/paper-OPL/","content":"本文提出了一个简单的损失函数OPL, Orthogonal Projection Loss，以保持 特征空间 上的正交性。OPL 和交叉熵损失组合使用，且没有额外的学习参数，因而可以植入现有的任何包含交叉熵损失的深度神经网络模型中。\n\n\n基本信息\n论文标题：Orthogonal Projection Loss.[1]\n作者：Kanchana Ranasinghe, Muzammal Naseer, Munawar Hayat, Salman Khan, Fahad Shahbaz Khan\nPDF：arxiv[2]\n代码：Github[3]\n\n介绍背景本文对 Softmax交叉熵损失  开刀，可以看作给交叉熵损失加了个 Buff。作者观察到：交叉熵损失虽然鼓励了某个样本在正类向量（通常是 one-hot 形式）上的投影比负类向量高，但是没有 显式 的让不同类别的样本足够分开。基于此，作者开发了一个新的损失函数 正交投影损失, OPL，通过在 mini-batch 上的特征空间里显式地进行类内内聚和类间分离，弥补了交叉熵损失的不足。\n竞品分析\n以下内容均来源于本文[1]的自卖自夸，没来得及确认，不代表个人观点（逃\n\n损失函数们：\n\nContrastive  和  Triplet  损失：严重依赖于负样本（评：其实现在有压根不需要负样本的对比学习方法。如：BYOL）。而 OPT 直接在 mini-batch 上操作，不依赖负样本；\n基于 Center Loss [4]的方法们，引入了额外的学习参数[5]。而 OPT 没有额外参数；\n强行加一个 margin ，比如加一个固定的欧式的 margin  的方法们。这些方法的缺点是：1.  与交叉熵结合的不自然，而且可能会学到负相关性，也就是说本来两个类别已经隔的很远了，你却还要关注他们，让它们再远一点。而后面可以看到，OPT 就“自然”多了，它强化的是 CE 本身就有的属性（正交性）；\n基于  Angular Margin[6] 的方法们， 在人脸识别上效果优异，其内在的假设对于其他计算机视觉任务可能不具有一般性。而 OPT 可以植入任何 DNN 中；\n其他依赖具体网络结构的方法，如这篇论文[7]。而 OPT 不依赖具体模型结构；\n其他基于特征空间正交性的方法们依赖于 SVD ，数值不稳定。\n\n本文贡献\n提出了一个新的损失函数 OPT；\nOPT 算法可以很好的向量化加速；\n在多个任务验证了 OPT 的有效性，包括：各种图像分类任务、小样本任务、域自适应任务。并且具有很好的鲁棒性，如应对 对抗攻击 和 噪音标签 上。\n\n具体方法SCE Loss 的分析Sofmax 交叉熵损失的公式如下：\n有一些方法改进 CE 来扩大决策边界[8]：\n\n\n\n详见[8]，这些方法的缺点是梯度不好算以及 cos 函数不单调什么的，所以现有方法都用了数学近似。\nOP Loss 形式OP Loss 的定义如下，也就是让  趋近于 1， 趋近于0：\n 表示一个 mini-batch。\n\nPytorch 代码如下，可以看到，OPL 算法很好的向量化加速：\n\n\n另外，没有权重的 OPL 损失可以写作如下形式：【】\nOP Loss 分析正交性分析作者做了正交性的可视化如下图，颜色代表某两个类之间的夹角余弦值，具体分析详见原文[1]：\n\n\n\n\n常量分析下图分别是特征正交性、同类相似性和不同类相似性随训练的变化：\n\n\n\n\n实验这里罗列一些实验结果，更多结果见原文[1]。\n图像分类CIFAR-100 和 ImageNet\n\n\n\n预测质量分析\n\n\n\n小样本学习\n\n消融实验\n\n总结\n本文提供了一个简单和有效的损失，可以用在各种模型上；\n可以探讨该方法在无监督学习中的效果。\n\nReference[1]Ranasinghe, K., Naseer, M., Hayat, M., Khan, S. &amp; Khan, F. S. Orthogonal Projection Loss. (2021). arxiv  ↩[2]arxiv  ↩[3]Github | Pytorch  ↩[4][ECCV 2016] A Discriminative Feature Learning Approach for Deep Face Recognition  ↩[5]类中心 c 是一个参数  ↩[6]Liu W, Wen Y, Yu Z, et al. SphereFace: Deep Hypersphere Embedding for Face Recognition[J]. arXiv preprint arXiv:1704.08063, 2017.  ↩[7]Guolei Sun, Salman Khan, Wen Li, Hisham Cholakkal, Fahad Khan, and Luc Van Gool. Fixing localization errors to improve image classification. ECCV, 2020  ↩[8]Deng, J., Guo, J., Xue, N. &amp; Zafeiriou, S. ArcFace: Additive Angular Margin Loss for Deep Face Recognition. arXiv:1801.07698 [cs] 2019  ↩","categories":["论文笔记","损失函数"],"tags":["论文笔记","小样本","损失函数"]},{"title":"测试首页隐藏功能","url":"/2021/test-to-hide-the-article-on-the-home-page/","content":"这是一篇用来测试首页隐藏功能的测试贴。如果不出意外，这篇文章并不会在首页演示。\n为什么可能有的文章并不适合在首页展示，但需要罗列在归档中。\n如何做修改源码文章内加入 hide 字段，然后修改 hexo-pagination 包的 lib\\pagination.js 文件，添加如下代码：\n// if (base &amp;&amp; !base.endsWith(&#x27;/&#x27;)) base += &#x27;/&#x27;;posts = posts.filter(p =&gt; !p.hide)// const &#123; length &#125; = posts;\n\n替换官方包简单打包了一下，也可以直接修改官方包如下：\nyarn remove hexo-generator-indexyarn add hexo-generator-index-tilden","categories":["技术","Hexo"],"tags":["Hexo"]},{"url":"/404/index.html","content":"\ndocument.title = '页面未找到';\nif (document.querySelectorAll('head link.style404').length === 0) {\n    (function(d) {\n    const s1 = d.createElement('link');s1.classList.add(\"style404\");\n    s1.rel='stylesheet';s1.href = '/css/404.css';\n    (d.getElementsByTagName('head')[0]).appendChild(s1);\n    })(document)\n}\n\n您访问的页面未找到\n\n\n\n\n\n\n \n返回 首页"},{"title":"about","url":"/about/index.html","content":"About me"},{"title":"links","url":"/links/index.html","content":"申请友链就按照下面的格式回复就好啦，看到会加上~\n- name: # &lt;站点名称&gt;  link: https://example.com/  description: # &lt;一句话描述&gt;  avatar: # &lt;头像url&gt;"},{"title":"categories","url":"/categories/index.html","content":""},{"title":"tags","url":"/tags/index.html","content":""},{"title":"我现在在做什么","url":"/now/index.html","content":"我现在在做什么\n最后更新：2021年4月28日\n\n本页面灵感来自 nownownow[1]。\n现况在大连读研[2]，已经学完了所有课程，也考完了所有的试，现在每天主要的事情大概就剩看论文和写实验室的项目了吧 :/。另外闲时尽量做些有趣的事情，比如 学前端 、看 Mooc 以及 谈恋爱。最近也在尝试坚持跑步🏃‍♂️。\n正在做的事\n合伙创业项目的开发。\n看 小样本学习[3] 和 自监督学习[4] 方面的论文和代码。\n实验室的项目们：大连湾、智慧农业、东北电力知识图谱。\n看 CS224W [5] 网课。\n学前端。\n控糖😢。\n\n正在看的书\nPython深度学习基于PyTorch[6]\n\nReference[1]nownownow.com  ↩[2]SSDUT  ↩[3]Meta learning  ↩[4]Unsupervised learning  ↩[5]CS224W | Home  ↩[6]电子版  ↩"}]