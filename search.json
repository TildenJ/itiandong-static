[{"title":"使用 Jenkins 和 Gitee 自动部署博客","url":"/2021/automating-blog-deployment-with-jenkins-and-gitee/","content":"本文介绍如何在自建服务器上使用 Jenkins 和 Gitee 自动部署博客。\n\n\n\n最近给域名备了个案，于是花了点时间把博客从 Vercel 迁移到了国内服务器上。之前用的 Vercel 是能够在 Git 仓库发生变更后自动部署的，但迁到自建服务器上后这个功能就得自己实现了，搜索了一下实现方案，最后选用了 Jenkins。\n环境信息\n\n\n环境\n版本\n\n\n\n操作系统\nCentOS 7\n\n\nJenkins\n2.277.4\n\n\nJDK\n1.8.0_282\n\n\nNginx\n1.18.0\n\n\nGit Host\nGitee\n\n\n配置 Jenkins安装 Jenkins参考 官方文档 安装即可， CentOS 的步骤如下 ：\n# 添加 Yum 源sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo# 导入密钥sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keysudo yum install -y jenkins\n\n（可选）Jenkins 默认端口为 8080，可以在配置文件里修改：\nvim /etc/sysconfig/jenkins# 修改 JENKINS_PORT=xxx 即可\n\n最后添加开机启动：\n# 重载服务（由于前面修改了 Jenkins 启动脚本）sudo systemctl daemon-reload# 启动 Jenkins 服务sudo systemctl start jenkins# 将 Jenkins 服务设置为开机启动# 由于 Jenkins 不是 Native Service，所以需要用 chkconfig 命令而不是 systemctl 命令sudo /sbin/chkconfig jenkins on\n\nJenkins 初始化确保之前设置的端口在防火墙里已开放，然后浏览器访问 &lt;ip&gt;:&lt;port&gt;，按照向导一步步完成初始化。\n安装插件安装配置 NodeJS Plugin登录 Dashboard，选择 Manage Jenkins &gt; Manage Plugins，点击 Available，安装 NodeJS Plugin。\n然后在 Dashboard &gt; Manage Jenkins &gt; Global Tool Configuration 里下滑找到 NodeJS ，点击 NodeJS installations …，配置如下：\n\n\n选择 Node 版本，在 Global npm packages to install 里填入 Hexo 和 Yarn 依赖：\nhexo-cli@4.2.0 yarn --registry https:&#x2F;&#x2F;registry.npm.taobao.org&#x2F; \n\n点 Save 保存。\n安装 Gitee Plugin由于 Github 在国内网络几乎不可用，这里把 Host 换成了 Gitee，因此还需要安装一个 Gitee Plugin。\nGitee 的配置参考 Gitee 的官方帮助中心：\n简单来说，在 Jenkins -&gt; Manage Jenkins -&gt; Configure System -&gt; Gitee Configuration -&gt; Gitee connections 里，按照文档配置如下：\n\n\n添加 CI 任务配置密钥（可跳过）由于我博客项目设置为了私人仓库，所以需要额外生成密钥对并把公钥添加到 Gitee 里，如果你的仓库是公开状态，这一步可以跳过：\n切换到 Jenkins 用户：\nsudo su -s /bin/bash jenkins\n\n生成密钥对：\nssh-keygen -o\n\n查看公钥并复制：\ncat ~&#x2F;.ssh&#x2F;id_rsa.pub\n\n然后在 Gitee 网站右上角 个人头像 &gt; 设置 &gt; SSH公钥 里粘贴公钥，点确定保存。\n新建任务新建任务接下来就可以在 Jenkins 里新建构建博客的 CI 任务了！\n打开 Dashboard，点击 New Item。输入 Item name，类型选择 Freestyle project。配置页里 Gitee connection 选择之前配置的 connection。\n在 Source Code Management 里选择 Git，Repository URL 里填入仓库链接，如果这个时候显示权限失败，请返回上一小节配置密钥。\n在 Build Triggers 里选择 Build when a change is pushed to Gitee. Gitee webhook URL: http://81.70.155.173:8089/gitee-project/blog ，注意复制这里的 webhook url，之后会用到。\n然后再 Enabled Gitee triggers 里选中 Push Events，Secret Token for Gitee WebHook 里点击 Generate，同样保存备用。\nGitee 配置 Webhook之前配置的 Webhook 需要在 Gitee 上同样配置一下才能正常工作：\n登陆 Gitee 后在仓库主页点击 管理 &gt; WebHooks &gt; 添加 WebHooks，然后填入刚刚保存的 url 和 token，保存即可。\n编写构建脚本回到任务配置页，继续添加自动构建脚本：\n在 Build 里点击 Add build step，选择 Execute shell，根据网站和博客的具体情况编写构建部署命令如下：\n# 不安装 devDependencesyarn install --prod --registry https://registry.npm.taobao.org/# Hexo 生成脚本hexo cleanhexo generate# 部署脚本rm -rf /www/wwwroot/mysite/*cp -a ./public/. /www/wwwroot/mysite/\n\n2021年5月28日 更新，部署 mkdocs 的脚本如下：\n/usr/bin/pip3.6 install -i https://pypi.tuna.tsinghua.edu.cn/simple mkdocs-material --user/usr/bin/python3 -m mkdocs buildrm -rf /www/wwwroot/mymkdocssite/*cp -a ./site/. /www/wwwroot/mymkdocssite/\n\n测试部署完成 CI 任务的创建后，回到 Project 页面，点击 Build now，观察是否一切正常。然后通过 Git 更改后 push，测试 WebHook 是否正常。\n如果部署时提示权限不足，可以把网址所在的目录 owner 改为 jenkins 来解决。\nsudo chown -R jenkins:jenkins mysite/\n\n其他推送原来用 Vercel 的时候，每次构建完毕，Vercel Bot 就会给我的仓库的 Commit 评论一下，然后会收到 Github 发来的邮件，提醒我构建完成，非常好用。当然，现在这个功能也只能自己写了。因为是国内服务器，直接排除了用 Telegram 推送。搜索了一下，发现了一个通过 QQ 推送消息的网站 Qmsg酱，按照文档注册配置后可以获得一个 Qmsg Key，然后就可以调用 RESTful 接口发起推送了！\n配置非常简单，在构建脚本的最后添加如下命令即可：\ncurl --location --request POST &#x27;https://qmsg.zendee.cn/send/&lt;你的 qmsgKey&gt;&#x27; \\--header &#x27;Content-Type: application/x-www-form-urlencoded&#x27; \\--data-urlencode &#x27;msg=itiandong.com 部署成功&#x27;\n\n这样每次部署完成，你会收到一条 QQ 消息：\n\n\n国内网络的坑这次迁移的过程中也遇到了一些坑。最开始本来打算沿用 Github 的，但测试发现 Clone 总是出错，于是被迫改成国内的 Gitee。可以在原仓库上额外添加 Gitee 远程仓库地址，让 Github 和 Gitee 并存：\ngit remote add gitee &lt;url&gt;\n\n然后提交时，分别执行：\ngit push origin mastergit push gitee master\n\n就可以分别提交到两个仓库里了。\n另外，博客用到的一个插件 hexo-all-minifier  也遇到了类似的问题。这个插件的安装脚本 install.js 会从 githubusercontent.com 里下载文件，而国内这个域名直接被 ban 了… 无语…于是我暂时去掉了这个插件，如果想解决可能需要重打包一下了…\n刚尝试重打包了一下，太麻烦了，怕了怕了，还是换个包吧。\n","categories":["技术","Hexo"],"tags":["Hexo","CI","Jenkins","博客","配置"]},{"title":"博客添加了脚标功能！","url":"/2021/footnotes-test/","content":"这是一篇用来测试脚标功能的测试贴。今天想给博客整个脚标参考文献功能，搜索一番发现并没有合适的包。于是花了一下午时间，基于 hexo-reference[1] 重写了下，修复了一些 Bug。然后主要是把解析器改成了博客正在用的 marked（原包使用的 markdown-it ），以及把原来的 Hint.css 改为更加好看的 Tippy.js[2]。\n功能测试Markdown 原文\n\n渲染结果\n\n基本脚注[3]，点击可以跳转到相应的参考文献。\n这是行内脚标[4]，行内脚标支持 Markdown。\n这是个带图片的脚标[5]\n\n\n渲染结果就是上面这样子啦！桌面端鼠标放在上标上会有内容弹窗[6]，触屏设备则需要按住不动 0.5 秒，该行为可以在 Tippy.js 中设置[7]。\nTODO\n 有时间打包成插件公开出来；\n 定位不准的问题；\n 定位后高亮提示;\n a 链接与 touch 操作矛盾；\n 引用自动编号功能；\n 同一文献多处引用的功能；\n\nReference[1]hexo-reference 仓库↩[2]Tippy.js 官网↩[3]基本脚注。↩[4]行内参考文献↩[5]图片脚标 \n↩[6]内容弹窗↩[7]Tippy.js &gt; All Props &gt; touch↩","categories":["技术","Hexo"],"tags":["Hexo","脚标","参考文献"]},{"title":"Google Colaboratory 小技巧","url":"/2021/colab-tips/","content":"最近在用 Google Colaboratory 跑实验，开一贴用来记录、整理一些使用过程中发现的小技巧。不定期更新。\n\n\n修订记录\n2021年5月14日 初版目录\n\n白嫖无限盘存储数据集Colab 是可以挂载 Google Drive 来导入训练需要的数据集的，但 Google Drive 只有 15Gb 的免费空间，稍微多放几个数据集空间就不够用了。为了解决这个问题，你当然可以直接花钱购买存储空间，100Gb 空间的价格差不多是 2 美元一个月。但鉴于数据集也不是啥隐私数据（主要是穷），于是我就找了些免费的团队盘来存储。团队盘大概是谷歌云盘的企业方案提供的功能，企业可以建立一个独立的团队盘，无空间限制并且可以自由添加管理员或者内容管理者。团队盘和云盘用起来没啥区别，都可以挂载到 Colab 里，但并不稳定（可能会被企业回收）且企业管理员可以看到所有团队盘的内容，所以不要在里面放任何隐私文件！\n至于如何申请到免费的团队盘。在 Youtube 上搜到了一个视频教程，里面给出了一些网址如下图，只试了第一个网址就成功申请到了：\n\n\n\n\n免费账户使用高内存高算力GPU之前在推特上刷到一个免费用户白嫖 P100 的推文，只要使用指定的 ipynb 文件就能申请到 P100。当时看到也第一时间尝试了一下，果然可以 100% 申请到 P100，而且还是高内存机器！笔记本地址：P100.ipynb。\n不过我最近也没有这样用过了，也不知道现在（2021年5月14日）这个方法还能不能稳定使用，刚尝试了一次，申请到的是较弱的 Tesla T4。 至于为啥最近没有这样用了，因为… 我氪金上 Colab Pro了（手动狗头）\n\n\n在 Colaboratory 中运行 Shell 命令Colab 实际上是一个在线的 Jupyter notebook，在 notebook 里，可以在命令行前加上”!”执行 Shell 命令：\n!pip install xxx\n\n但这样是存在缺陷的，当通过这种方式执行命令时，脚本会在一个临时的 SubShell 里执行，所以譬如运行 !cd EpicWord 的命令时是没有达到预期效果的（当然这里可以用 magic methods %cd 改变工作目录，或者直接用 automagic methods cd，后文也会提到）。一个优雅地运行 Shell 命令的方式是使用工具函数 run，该函数接受命令列表和工作路径，创建对应的 sh 脚本，自动 cd 到工作目录并按顺序执行命令：\n&quot;&quot;&quot;Helper to run command formated in python.&quot;&quot;&quot;def run(cmds, root=&quot;/content&quot;):  if not isinstance(cmds, list):    cmds = [cmds]  os.system(f&quot;echo cd &#123;root&#125; &gt; cmd.sh&quot;)  for cmd in cmds:    os.system(f&quot;echo &#123;cmd&#125; &gt;&gt; cmd.sh&quot;)  !bash cmd.sh\n\n用起来非常方便，一些例子如下：\n# 查看 GPU 信息run(&quot;nvidia-smi&quot;)# 解压准备数据集run([     f&#x27;tar -xf &#123;mini_imagenet_tar_dir&#125;/train.tar -C &#123;ds_target_dir&#125;&#x27;,     f&#x27;tar -xf &#123;mini_imagenet_tar_dir&#125;/test.tar -C &#123;ds_target_dir&#125;&#x27;,     f&#x27;tar -xf &#123;mini_imagenet_tar_dir&#125;/val.tar -C &#123;ds_target_dir&#125;&#x27;,])# 更新实验代码run(&quot;git pull&quot;, f&quot;/content/&#123;repository&#125;&quot;)# 运行模型代码run(    r&#x27;python train_fsl.py --save_dir /content/drive/MyDrive/savedirs  --max_epoch 200 ...&#x27;,    f&quot;/content/&#123;repository&#125;&quot;)\n\n这种方式可以满足大部分运行命令行的需求，顺带提一句，如果你想在当前笔记本的 IPython 环境里运行 Python 代码，可以这样做：\n%cd EpicWork%run main.py\n\n使用 Github 私人仓库托管代码使用 Tensorboard 监控实验状态Telegram 推送训练日志","categories":["技术","Colab"],"tags":["Colab","实验","深度学习"]},{"title":"论文笔记：Orthogonal Projection Loss","url":"/2021/paper-OPL/","content":"\nWarning: 经过实验验证，本文的方法没啥作用，初步判断对于卷积神经网络提升不大。\n\n本文提出了一个简单的损失函数OPL, Orthogonal Projection Loss，以保持 特征空间 上的正交性。OPL 和交叉熵损失组合使用，且没有额外的学习参数，因而可以植入现有的任何包含交叉熵损失的深度神经网络模型中。\n\n\n基本信息\n论文标题：Orthogonal Projection Loss.[1]\n作者：Kanchana Ranasinghe, Muzammal Naseer, Munawar Hayat, Salman Khan, Fahad Shahbaz Khan\nPDF：arxiv[2]\n代码：Github[3]\n\n介绍背景本文对 Softmax交叉熵损失  开刀，可以看作给交叉熵损失加了个 Buff。作者观察到：交叉熵损失虽然鼓励了某个样本在正类向量（通常是 one-hot 形式）上的投影比负类向量高，但是没有 显式 的让不同类别的样本足够分开。基于此，作者开发了一个新的损失函数 正交投影损失, OPL，通过在 mini-batch 上的特征空间里显式地进行类内内聚和类间分离，弥补了交叉熵损失的不足。\n竞品分析\n以下内容均来源于本文[1]的自卖自夸，没来得及确认，不代表个人观点（逃\n\n损失函数们：\n\nContrastive  和  Triplet  损失：严重依赖于负样本（评：其实现在有压根不需要负样本的对比学习方法。如：BYOL）。而 OPT 直接在 mini-batch 上操作，不依赖负样本；\n基于 Center Loss [4]的方法们，引入了额外的学习参数[5]。而 OPT 没有额外参数；\n强行加一个 margin ，比如加一个固定的欧式的 margin  的方法们。这些方法的缺点是：1.  与交叉熵结合的不自然，而且可能会学到负相关性，也就是说本来两个类别已经隔的很远了，你却还要关注他们，让它们再远一点。而后面可以看到，OPT 就“自然”多了，它强化的是 CE 本身就有的属性（正交性）；\n基于  Angular Margin[6] 的方法们， 在人脸识别上效果优异，其内在的假设对于其他计算机视觉任务可能不具有一般性。而 OPT 可以植入任何 DNN 中；\n其他依赖具体网络结构的方法，如这篇论文[7]。而 OPT 不依赖具体模型结构；\n其他基于特征空间正交性的方法们依赖于 SVD ，数值不稳定。\n\n本文贡献\n提出了一个新的损失函数 OPT；\nOPT 算法可以很好的向量化加速；\n在多个任务验证了 OPT 的有效性，包括：各种图像分类任务、小样本任务、域自适应任务。并且具有很好的鲁棒性，如应对 对抗攻击 和 噪音标签 上。\n\n具体方法SCE Loss 的分析Sofmax 交叉熵损失的公式如下：\n有一些方法改进 CE 来扩大决策边界[8]：\n\n\n\n详见[8]，这些方法的缺点是梯度不好算以及 cos 函数不单调什么的，所以现有方法都用了数学近似。\nOP Loss 形式OP Loss 的定义如下，也就是让  趋近于 1， 趋近于0：\n 表示一个 mini-batch。\n\nPytorch 代码如下，可以看到，OPL 算法很好的向量化加速：\n\n\n另外，没有权重的 OPL 损失可以写作如下形式：【】\nOP Loss 分析正交性分析作者做了正交性的可视化如下图，颜色代表某两个类之间的夹角余弦值，具体分析详见原文[1]：\n\n\n\n\n常量分析下图分别是特征正交性、同类相似性和不同类相似性随训练的变化：\n\n\n\n\n实验这里罗列一些实验结果，更多结果见原文[1]。\n图像分类CIFAR-100 和 ImageNet\n\n\n\n预测质量分析\n\n\n\n小样本学习\n\n消融实验\n\n总结\n本文提供了一个简单和有效的损失，可以用在各种模型上；\n可以探讨该方法在无监督学习中的效果。\n\nReference[1]Ranasinghe, K., Naseer, M., Hayat, M., Khan, S. &amp; Khan, F. S. Orthogonal Projection Loss. (2021). arxiv↩↩↩↩[2]arxiv↩[3]Github | Pytorch↩[4][ECCV 2016] A Discriminative Feature Learning Approach for Deep Face Recognition↩[5]类中心 c 是一个参数↩[6]Liu W, Wen Y, Yu Z, et al. SphereFace: Deep Hypersphere Embedding for Face Recognition[J]. arXiv preprint arXiv:1704.08063, 2017.↩[7]Guolei Sun, Salman Khan, Wen Li, Hisham Cholakkal, Fahad Khan, and Luc Van Gool. Fixing localization errors to improve image classification. ECCV, 2020↩[8]Deng, J., Guo, J., Xue, N. &amp; Zafeiriou, S. ArcFace: Additive Angular Margin Loss for Deep Face Recognition. arXiv:1801.07698 [cs] 2019↩↩","categories":["论文笔记","损失函数"],"tags":["论文笔记","小样本","损失函数"]},{"title":"你好，世界","url":"/2021/hello-world/","content":"这个人很忙，正在复习《凸优化方法》，一会儿回来…\n\n\n测试目录我爱优化方法\n测试测试公式\n\n\n测试图片\n测试代码print('我爱优化方法')","categories":["日常"],"tags":["Hello World"]},{"title":"Grub 报错 unknown filesystem 的修复","url":"/2019/fix-for-grub-error-unknown-filesystem/","content":"\nWarning: 这是一篇从硬盘里翻出来的旧文\n\n记录了下在安装 Manjaro 的基础上安装 Windows 10 而导致的 grub 引导失败报 unknown filesystem 的修复过程。\n\nTL;DR适用于 UEFI ！！！\ngrub rescue\n迭代 ls 找到 manjaro 所在的分区 (hdx,gptx)set prefix&#x3D;(hdx,gptx)&#x2F;boot&#x2F;grubset root&#x3D;hdx,gptxinsmod normalnormal\n\n进入系统后\nmount | grep /boot/efi # 找到 efi 所在分区 /dev/sdaxsudo update-grubsudo grub-install /dev/sdax\n\n完结撒花！\n问题描述因为种种原因，需要在笔记本上临时装个 Win10。于是找到启动盘，安装镜像，一顿操作后重启。发现居然直接进了 Win10 ，隐约感觉有点不对劲，但忍住疑惑开始边进行繁琐的 Win10 配置， 边观看世界赛半决赛 T1 vs G2。配置的差不多后重启进入 Manjaro 却悲剧了。告诉我引导失败，报了 unknown filesystem，并贴心的进入了 grub rescue 模式。这时反应过来可能是安装工具改了磁盘挂载导致 grub 加载失败。\n解决Grub 运行模式Grub 有两种运行模式， normal 和 rescue ，normal 就是正常情况下那个包含了菜单界面的模式，而当 grub 发现错误时，就会进入 rescue 模式\nrescue 的常用命令如下：\n\n\n\n\n说明\n\n\n\nset\n查看、编辑环境变量\n\n\nls\n查看分区信息\n\n\ninsmod\n加载模块\n\n\n修复 grub 配置\n使用 ls 命令，列出所有分区。\n依次使用 ls (分区)/ 命令，直到分区可读且列出了 Manjaro 的 / 为止。记下根目录所在分区 (hdx,gptx)。\n输入 set prefix=(hdx,gptx)/boot/grub 和 set root=hdx,gptx，更改环境变量 prefix 和 root。\n执行 insmod normal 载入 normal 模块\n执行 normal 进入 normal 模式，此时应该可以正常引导进入 Manjaro.\n\n（可选）控制台模式该小节来自网络，没有尝试过\n进入普通模式，出现菜单，如果加载grub.cfg（错误的）可能出现问题，按shift可以出现菜单，之后按c键进入控制台\n\n进入正常模式后就会出现grub&gt;这样的提示符，在这里支持的命令就非常多了。 \n引导系统\nset root&#x3D;(hd0,msdos1)  #设置正常启动分区linux &#x2F;boot&#x2F;vmlinuz ....  ro text root&#x3D;&#x2F;dev&#x2F;sda1  #加载内核，进入控制台模式initrd  &#x2F;boot&#x2F;initrd ....  #加载initrd.imgboot #引导\n\n更新 grub进入系统后，打开终端：\n\n执行 mount | grep /boot/efi，记下 efi 分区的位置 /dev/sdax\n执行 sudo update-grub ，该操作会自动检测安装的操作系统，更新 grub 菜单。\n执行 sudo grub-install /dev/sdax，重新安装。\n\n","categories":["技术","grub"],"tags":["grub","manjaro","uefi"]},{"title":"论文笔记：从 JPEG 中学习","url":"/2021/paper-learning-from-JPEG/","content":"这几天看了一些利用图像 DCT 系数作为空间特征训练卷积神经网络的论文，感觉挺好玩的，这里这里做一下整理总结。\n\n\nWarning: 还没写完！好多内容还没看！\n\n编写记录\n2021年5月26日 09 点 编写目录；\n2021年5月26日 10 点 看完博客，写了点；\n2021年5月26日 17 点 看了会儿论文，写了点；\n2021年5月29日 加了 DCT 公式和代码实现。\n\nJPEG 算法本节主要参考维基百科[4]和该系列博客[8]。\n\n 联合图像专家小组（英语：Joint Photographic Experts Group，缩写：JPEG）[4]是一种针对照片影像而广泛使用的有损压缩标准方法。使用 JPEG 格式压缩的图片文件一般也被称为 JPEG Files，最普遍被使用的扩展名格式为.jpg，其他常用的扩展名还包括.jpeg、.jpe、.jfif以及.jif。\nJPEG/JFIF 是互联网上最普遍的被用来存储和传输彩色照片的格式。\n\nJPEG 编码的主要流程如下图所示，从图中可以看出，在 JPEG 编码中， RGB格式的图像首先会被转换成YCbCR色彩空间，随后，图像的每个通道会分别进行不同的下采样。采样完成后接着进行量化的 DCT 计算得到量化的 DCT 系数，最终使用霍夫曼编码对数据进行无损压缩。\n\n\n以 24bits/pixel 的彩色图片为例，具体来说，一个常见的 JPEG 算法过程分为 7 过程：色彩空间转换（Color space transformation、降采样（Downsampling）、区块分割（Block splitting）、离散余弦变换（Discrete cosine transform）、量化（Quantization）、熵编码（Entropy coding）和解码（Decoding）。\n色彩空间转换（Color space transformation） - 无损这一步的主要目的是把原始图像的色彩空间从 RGB 转换为 YCbCr。\n\n所谓颜色空间，是指表达颜色的数学模型[5]。 YCbCr 模型广泛应用在图片和视频的压缩传输中，Y表示亮度(Luminance)，Cb和Cr分别表示绿色和红色的色度成分 chroma components。对于人眼来说，图像中明暗的变化更容易被感知到，这是由于人眼的构造引起的。视网膜上有两种感光细胞，能够感知亮度变化的视杆细胞，以及能够感知颜色的视锥细胞，由于视杆细胞在数量上远大于视锥细胞，所以我们更容易感知到明暗细节。\n\n这两种色彩空间的示意图如下：\nRGB 色彩空间：\n\n\nYCbCr 色彩空间：\n\n\n可以明显看到，亮度图的细节更加丰富。而 JPEG 算法的主要思想，就是在尽可能保留 Y 通道的前提下，大幅度压缩色度通道，即 JPEG  把图像转换为 YCbCr 之后，就可以针对数据的重要程度的不同做不同的处理。这也是为什么 JPEG 使用这种颜色空间的原因。\n从 RGB 到 YCbCr 的一个转换计算公式如下：\n\n\n\n\n降采样（Downsampling） - 有损\n 这一步又称为 色度抽样 [6]。简单来说也是根据人类视觉系统（HVS）的特性，对亮度和色度进行不同策略的采样，一般来说，会对亮度不采样而对色度大幅采样。\n\n\n\n如上图，抽样系统中通常用一个三分比值 J:a:b 来表示某个方案。JPEG 中最常用的是 4:2:0：\n\nJ：水平抽样总数，通常为4。\na：第一行中的抽样数目。\nb：第二行中的额外抽样数目。\n\n区块分割（Block splitting） - 无损完成色度抽样后，随后将每个通道分割成 8×8 块。根据不同大小色度抽样产生不同大小的最小编码单元块（MCU）。其中 8×8 的选取是依据经验，在计算复杂度和算法效果中均衡得出的。\n至于边界处理，有一些边界填充技术。\n离散余弦变换（Discrete cosine transform） - 无损完成区块分割后，接着把分割出来的每一个 8×8 的子区域，使用二维的离散余弦变换（DCT）转换到频率空间。离散余弦变换[7]类似于离散傅里叶变换，但是只使用实数，相当于一个长度大概是它两倍的离散傅里叶变换。\nDCT 是 JPEG 算法的核心。1807 年，39 岁的傅里叶在他的一篇论文里提出了一个想法，他认为任何周期性的函数，都可以分解为为一系列的三角函数的组合。而对于离散的数据而言，如果离散的输入数据是对称的话，那么傅里叶变化出来的函数只含有余弦项，这种变换称为离散余弦变换。也就是说，经过 DCT 变换，可以把一个数组分解成数个数组的和，如果我们数组视为一个一维矩阵，那么可以把结果看做是一系列矩阵的和。\n对于彩色图像而言，每一个 8×8×3 的输入矩阵，经过一个二维 DCT 变换后，得到 8×8×3 的输出，也就是 DCT 系数。\n下图是 64 个基本余弦波，这64个余弦波，可以组合成任意 8*8 的图形。我们只要用系数（系数表示每个单独的余弦波对整体图像所做的贡献）对这64个余弦波进行加权，就可以表示出任何的图形。\n\n\n以最常用的 DCT-II 公式为例，其计算公式如下：\n对于一个二维的图像输入 ，位置 i, j 的 DCT 系数计算公式如下：\n\n\n\n\nDCT 逆的公式如下：\n\n\n\n\n根据公式，可以轻松地用 Numpy  实现，代码如下：\n# 系数矩阵def normalize(N):    n = np.ones((N, 1))    n[0, 0] = 1 / np.sqrt(2)    return (n @ n.T)# 基本余弦波def harmonics(N):    spatial = np.arange(N).reshape((N, 1))    spectral = np.arange(N).reshape((1, N))    spatial = 2 * spatial + 1    spectral = (spectral * np.pi) / (2 * N)    return np.cos(spatial @ spectral)def dct(im):    N = im.shape[0]    n = normalize(N)    h = harmonics(N)    coeff = (1 / np.sqrt(2 * N)) * n * (h.T @ im @ h)    return coeffdef idct(coeff):    N = coeff.shape[0]    n = normalize(N)    h = harmonics(N)    im = (1 / np.sqrt(2 * N)) * (h @ (n * coeff) @ h.T)    return im\n\n这里给出两个计算例子：\n\n全为 100 的矩阵：\n\n更通常的例子（取自维基百科[2]）：\n\n\n可以看到，数据经过DCT变化后，被明显分成了直流分量和交流分量两部分。图中，左上部分低频区的系数比较大，右下高频区的系数较小。鉴于人眼对高频区的识别不敏感，所以在下面量化部分可以舍弃一些高频区的数据。这里的 DCT 变化还没开始压缩。\n量化（Quantization） - 有损在 DCT 变化后，舍弃高频区数据的过程称为量化。JPEG 算法提供了两张标准的量化系数矩阵，分别用于处理亮度数据 Y 和色差数据 Cr 以及 Cb 。\n\n\n上表分别为亮度量化表和色彩量化表，表示 50% 的图像质量。这两张表中的数据基于人眼对不同频率的敏感程度制定的。\n量化表是控制 JPEG 压缩比的关键，可以根据输出图片的质量来自定义量化表，通常自定义量化表与标准量化表呈比例关系，表中数字越大则质量越低，压缩率越高。Photoshop 有 12 张量化表。\n量化时，用前面的量化矩阵与 DCT 矩阵逐项相除并取整。\n量化是有损的，在解码时，反量化会乘回量化表的相应值。由于存在取整，低频段会有所损失，高频段的0字段则会被舍弃，最终导致图像质量降低。\n熵编码（Entropy coding） - 无损得到量化后的矩阵就要开始编码压缩过程了，首先要把二维矩阵变为一维数组，这里采用了 zigzag 排列，将相似频率组在一起：\n\n\n这么做的目的只有一个，就是尽可能把 0 放在一起，由于 0 大部分集中在右下角，所以才去这种由左上角到右下角的顺序。\n最后对得到的整数数组进行哈夫曼压缩，得到最终的压缩数据，压缩详细过程略，注意哈夫曼压缩本身是无损的。\n解码（Decoding）解码来显示影像，把以上所有操作反过来走一遍就好了。\n使用 JPEG 编码的频域学习现在大部分基于图像的任务，都是通过 RGB 图像进行学习，也就是空域。而频域学习的意思就是将 RGB 图像变换到频域（例如 DCT ），然后在频域空间上进行学习。\nFaster Neural Networks Straight from JPEG[1]用 ResNet50 在大的分类数据集 ImageNet 上做了许多频域学习的实验。\n对于数据集中 JPEG 格式的图像，本文魔改了 libjpeg 库，丢掉了 JPEG 解码的最后一步计算，直接从原始图像得到 DCT 系数，然后直接输入卷积神经网络中。\n\n\n如果输入图像大小为 224×224，分为 8×8 的组块，一共 28×28 个块，输出 28×28 个系数矩阵。把相同频率（即系数矩阵相同位置）的系数按照位置关系放到同一个 channel 中，这样就得到了大小为 28×28，channel 数为 8×8×3=192 的 feature map。\n本文作者指出，该过程实际上等价于一个卷积操作，kernel size 为 8×8  ，stride 为 8×8，输入 channel 数为 1，输出 channel 数为64 。只不过卷积的参数不用学习，是先验的。而且卷积过滤器是正交的，参数化学习很难学到同样特性的过滤器参数。\n当然，为了适应新的输入，需要对原有的卷积神经网络的前几层进行少量的修改。经过测试，这篇文章的方法更快且精度更高，在达到同样精度的情况下能够比 Resnet50 基线快 1.77 倍。\n基于学习的通道筛选Learning in the Frequency Domain[3] 是达摩院发表在 CVPR 2010 的一项工作。提出的方法和 Faster Neural Networks Straight from JPEG[1]基本一样，主要贡献是在实例分割上做了些实验，验证了频域学习在实例分割任务上同样有效。另一个贡献就是提出了一个基于学习的通道选择，实验验证在 ImageNet 分类任务中，能够修剪多达 87.5% 的频率信道，而没有精度下降。\n\n\n上图就是这篇文章提出的 gate 模块，实现基于学习的频率通道选择。因为不同的通道代表了不同的频率，而有些频率（主要是高频）对于图像分类和实例检测任务的精度贡献有限，所以可以删除一些通道而不会影响模型精度。本文的 gate 模块对每一个频率通道置顶了一个二元评分，0 表示丢掉，1表示保留。这样做的结果就是输入数据的大小大幅减少，降低了计算复杂度和通信带宽。该门模块很简单，可以作为模型的一部分，应用于在线推理中。\n具体的，输入张量的形状为 H×W×C ，经过平均池化得到形状为 1×1×C 的张量 2 。随后再经过 1×1 的卷积得到形状为 1×1×C 的张量 3 。从张量 1 到张量 3 的部分实际上是一个两层的 squeeze-and-excitation block(SE-Block)，SE-Block 利用通道信息来强调信息量大的特征并抑制信息量小的特征。然后将张量 3 与两个可学习的参数相乘得到形状为 1×1×C×2 的张量 4，在推断阶段，张量 4 每一个通道的两个数归一化后作为选择该通道的概率，在 Bernoulli 分布中采样进行选择。\n又因为 Bernoulli 采样是不可微的，不能反向传播，所以需要一些数学近似。这篇文章使用的方法是 Gumbel Softmax trick，使得 Bernoulli 采样可以反向传播训练。\n实验略。\n总结频域学习的优点：\n\n图像处理更高效：直接魔改 libjpeg 包就能从原始 jpg 图像中直接得到图形输入，减少了转换为 RGB 色彩空间的开销。\n模型训练，推断更快：首先是 JPEG 算法本身就是一个有损图像压缩算法，所以输入带宽和计算开销变小了，其次是空域学习相当于给 CNN 前几层引入了一个很强的先验知识（直接定好的参数），所以让模型训练更容易。\n光明正大的作弊，更大的输入尺寸。\n\nReference[1]L. Gueguen, A. Sergeev, B. Kadlec, R. Liu, and J. Yosinski, “Faster Neural Networks Straight from JPEG,” in Advances in Neural Information Processing Systems, 2018, vol. 31. [Online]. Available↩↩[2]JPEG#Discrete_cosine_transform↩[3]K. Xu, M. Qin, F. Sun, Y. Wang, Y.-K. Chen, and F. Ren, “Learning in the Frequency Domain,” Feb. 2020, Accessed: May 17, 2021. [Online]. Available↩[4]JPEG - 维基百科，自由的百科全书↩↩[5]色彩空間- 维基百科，自由的百科全书↩[6]色度抽样- 维基百科，自由的百科全书↩[7]离散余弦变换- 维基百科，自由的百科全书↩[8]JPEG 算法解密↩","categories":["论文笔记","图像特征"],"tags":["论文笔记","JPEG","DCT","图像特征"]},{"title":"测试首页隐藏功能","url":"/2021/test-to-hide-the-article-on-the-home-page/","content":"这是一篇用来测试首页隐藏功能的测试贴。如果不出意外，这篇文章并不会在首页演示。\n为什么可能有的文章并不适合在首页展示，但需要罗列在归档中。\n如何做修改源码文章内加入 hide 字段，然后修改 hexo-pagination 包的 lib\\pagination.js 文件，添加如下代码：\n// if (base &amp;&amp; !base.endsWith(&#x27;/&#x27;)) base += &#x27;/&#x27;;posts = posts.filter(p =&gt; !p.hide)// const &#123; length &#125; = posts;\n\n替换官方包简单打包了一下，也可以直接修改官方包如下：\nyarn remove hexo-generator-indexyarn add hexo-generator-index-tilden","categories":["技术","Hexo"],"tags":["Hexo"]},{"url":"/404/index.html","content":"\ndocument.title = '页面未找到';\nif (document.querySelectorAll('head link.style404').length === 0) {\n    (function(d) {\n    const s1 = d.createElement('link');s1.classList.add(\"style404\");\n    s1.rel='stylesheet';s1.href = '/css/404.css';\n    (d.getElementsByTagName('head')[0]).appendChild(s1);\n    })(document)\n}\n\n您访问的页面未找到\n\n\n\n\n\n\n \n返回 首页"},{"title":"about","url":"/about/index.html","content":"About me"},{"title":"links","url":"/links/index.html","content":"申请友链就按照下面的格式回复就好啦，看到会加上~\n友链格式：\n- name: # &lt;站点名称&gt;  link: https://example.com/  description: # &lt;一句话描述&gt;  avatar: # &lt;头像url&gt;\n本站信息：\n- name: Tilden&#x27;s Notes  link: https://itiandong.com/  description: Tilden 的笔记  avatar: https://itiandong.com/images/avatar.jpg"},{"title":"我现在在做什么","url":"/now/index.html","content":"我现在在做什么\n最后更新：2021年4月28日\n\n本页面灵感来自 nownownow[1]。\n现况在大连读研[2]，已经学完了所有课程，也考完了所有的试，现在每天主要的事情大概就剩看论文和写实验室的项目了吧 :/。另外闲时尽量做些有趣的事情，比如 学前端 、看 Mooc 以及 谈恋爱。最近也在尝试坚持跑步🏃‍♂️。\n正在做的事\n合伙创业项目的开发。\n看 小样本学习[3] 和 自监督学习[4] 方面的论文和代码。\n实验室的项目们：大连湾政务、智慧农业、东北电力知识图谱。\n看 CS224W [5] 网课。\n学前端。\n控糖😢。\n\n正在看的书\nPython深度学习基于PyTorch[6]\n\nReference[1]nownownow.com↩[2]SSDUT↩[3]Meta learning↩[4]Unsupervised learning↩[5]CS224W | Home↩[6]电子版↩"},{"title":"categories","url":"/categories/index.html","content":""},{"title":"tags","url":"/tags/index.html","content":""}]